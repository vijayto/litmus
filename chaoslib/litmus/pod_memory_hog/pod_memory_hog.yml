---
- block: 

    - block: 

      - name: Select the app pod
        shell: >
          kubectl get pod -l {{ app_label }} -n {{ app_ns }}
          -o=custom-columns=:metadata.name --no-headers
          | shuf | head -1 
        args:
          executable: /bin/bash
        register: app_pod_name

      - name: Record app pod name
        set_fact:
          app_pod: "{{ app_pod_name.stdout }}"

      when: "app_pod is not defined or app_pod == ''"

    # here app_ns is the namespace of pod on which we are performing memory chaos 
    # in genric experiments app_ns is same as app_ns
    # in openebs experiments app_ns is the namespace where openebs is installed i.e, openebs
    - name: Identify the application node
      shell: >
        kubectl get pod {{ app_pod }} -n {{ app_ns }}
        --no-headers -o custom-columns=:spec.nodeName
      args:
        executable: /bin/bash
      register: app_node

    - name: Record app pod's node name
      set_fact: 
        app_node: "{{ app_node.stdout }}"

    - block: 
        - name: Generate a run id if not passed from the engine/experiment
          shell: echo $(mktemp) | cut -d '.' -f 2 | cut -c -6
          register: rand_string   

        - name: Record the run id
          set_fact:
            run_id: "{{ rand_string.stdout | lower }}"
      when: "run_id is not defined or run_id == ''"

    - block:

        - name: Record the application container
          shell: >
            kubectl get pods -n {{ app_ns }} -o jsonpath='{.items[?(@.metadata.name=="{{ app_pod }}")].spec.containers[0].name}'
          args:
            executable: /bin/bash
          register: container
  
        - name: Record the app_container
          set_fact:
            c_container: "{{ container.stdout }}"
  
      when: c_container is not defined or c_container == ''

    - name: Obtain Container ID of the target container
      shell: >
        kubectl get pods {{ app_pod }} -n {{ app_ns }} 
        -o jsonpath='{.status.containerStatuses[?(@.name=="{{ c_container }}")].containerID}'
        | awk -F 'docker://' '{print $2}' 
      args:
        executable: /bin/bash
      register: container_id

    - name: Record the app_container_id
      set_fact:
        c_container_id: "{{ container_id.stdout }}"
 
    - name: Patch the chaos params to memory stress job template
      template:
        src:  /chaoslib/litmus/pod_memory_hog/app_memory_stress.j2
        dest: /chaoslib/litmus/pod_memory_hog/app_memory_stress.yml
      vars:
        memory_stress_image: "{{ lib_image }}"

    ## RECORD EVENT FOR CHAOS INJECTION
    - include_tasks: /utils/common/generate-kubernetes-chaos-events.yml
      vars:
        stage: "ChaosInject"
        exp_pod_name: "{{ chaos_pod_name }}"
        engine_ns: "{{ c_ns }}"
        message: "Injecting {{ c_experiment }} chaos on {{ app_pod }} pod"
      when: "c_engine is defined and c_engine != ''"

    # Setting pod_running_status to nil
    - name: Setting pod_running_status to nil
      set_fact: 
        pod_running_status: ""
        
      # Pod Memory Hog pods creation is attempted for a total of 3 times, if it is not immediately schedulable due to transient node conditions
      # If the pod-memory-hog pod is not schedulable across these 3 tries, the experiment is failed with message indicating improper cluster state.
    - include_tasks: /utils/common/create_chaos_pod.yml
      vars:
        pod_ns: "{{ c_ns }}"
        c_path: "/chaoslib/litmus/pod_memory_hog/app_memory_stress.yml"
        pod_label: "name=app-memory-stress-{{ run_id }}"
      with_sequence: start=1 end=3

    # Failing the execution, If pod-memory-hog pod won't come to running state after three retries.
    - fail:
        msg: "pod_memory_hog lib failed, Unable to create as pod-memory-hog pod couldn't be scheduled on the {{ app_node }} node"
      when: "pod_running_status is not defined or pod_running_status != 'Running'"
 
    ## with a grace period of 2 min before memory stress job terminate
    - name: Calculate the total wait time for memory stress job
      set_fact:
        job_wait_time: "{{ ((c_duration|int) + 120)| int }}"

    - name: Wait until the memory stress job is completed
      shell: >
        kubectl get pods -l name=app-memory-stress-{{ run_id }} --no-headers -n {{ c_ns }}
        --no-headers -o custom-columns=:status.phase
      args: 
        executable: /bin/bash
      register: result
      until: "result.stdout == 'Succeeded'"
      delay: 1
      retries: "{{ job_wait_time }}"

    - block:

        - name: Tear down memory chaos infrastructure
          shell: >
            kubectl delete -f /chaoslib/litmus/pod_memory_hog/app_memory_stress.yml -n {{ c_ns }} 
          args:
            executable: /bin/bash

        - name: Confirm that the memory stress pod is deleted successfully
          shell: >
            kubectl get pods -l name=app-memory-stress-{{ run_id }} --no-headers -n {{ c_ns }}
          args:
            executable: /bin/bash
          register: result
          until: "'No resources found' in result.stderr"
          delay: 2
          retries: 90

      when: "pod_running_status is defined and pod_running_status == 'Running'"

  rescue: 

    - block: 

        - name: Tear down memory chaos infrastructure, if setup
          shell: >
            kubectl delete -f /chaoslib/litmus/pod_memory_hog/app_memory_stress.yml -n {{ c_ns }} 
          args:
            executable: /bin/bash
          when: "chaos_pod_result.rc == 0"
        
        - name: Confirm that the memory stress pod is not present
          shell: >
            kubectl get pods -l name=app-memory-stress-{{ run_id }} --no-headers -n {{ c_ns }}
          args:
            executable: /bin/bash
          register: result
          until: "'No resources found' in result.stderr"
          delay: 2
          retries: 90
      when: "(pod_running_status is defined and pod_running_status == 'Running') and chaos_pod_result is defined"

    - fail:
        msg: "pod_memory_hog lib failed"
      when: true